{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import *\n",
    "import torch\n",
    "import xml.etree.ElementTree as ET\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_method_parameters(method_signature):\n",
    "    match = re.search(r'\\((.*)\\)', method_signature)\n",
    "    if match:\n",
    "        parameters = match.group(1)\n",
    "        parameter_list = [param.strip() for param in parameters.split(',')]\n",
    "        return parameter_list\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "def replace_generics_with_object(method_name):\n",
    "    gen_types = [\"T\", \"O\", \"K\", \"V\", \"E\",\"L\",\"M\",\"R\"]\n",
    "    gen_types_arr=[]\n",
    "    for gen_type in gen_types:\n",
    "        gen_types_arr.append(gen_type+\"[]\")\n",
    "\n",
    "    params=extract_method_parameters(method_name)\n",
    "    params_replace=[]\n",
    "    for param in params:\n",
    "        if param in gen_types:\n",
    "            params_replace.append(\"java.lang.Object\")\n",
    "        elif param in gen_types_arr:\n",
    "            params_replace.append(\"java.lang.Object[]\")\n",
    "        else:\n",
    "            params_replace.append(param)\n",
    "    method_name=method_name[:method_name.find(\"(\")]+f\"({','.join(params_replace)})\"\n",
    "    return method_name\n",
    "\n",
    "\n",
    "def extract_simple_name(full_name:str):\n",
    "    method_name=full_name[:full_name.find(\"(\")]\n",
    "    simple_name=method_name[method_name.rfind(\".\")+1:]\n",
    "    params=full_name[full_name.find(\"(\"):]\n",
    "    simple_name=simple_name+params\n",
    "    return simple_name\n",
    "\n",
    "\n",
    "def method_name_match(name_xml:str,names_csv:list,simple_names_csv:list):\n",
    "    name_xml_tran=replace_generics_with_object(name_xml)\n",
    "    if name_xml in names_csv:\n",
    "        return names_csv.index(name_xml)\n",
    "    if name_xml_tran in names_csv:\n",
    "        return names_csv.index(name_xml_tran)\n",
    "    simple_name_xml=extract_simple_name(name_xml)\n",
    "    simple_name_xml_tran=extract_method_parameters(name_xml_tran)\n",
    "    if simple_name_xml in simple_names_csv:\n",
    "        idx=simple_names_csv.index(simple_name_xml)\n",
    "        if len(idx)>1:\n",
    "            return -1\n",
    "        return simple_names_csv.index(simple_name_xml)\n",
    "    if simple_name_xml_tran in simple_names_csv:\n",
    "        idx=simple_names_csv.index(simple_name_xml_tran)\n",
    "        if len(idx)>1:\n",
    "            return -1\n",
    "        return simple_names_csv.index(simple_name_xml_tran)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj shape: torch.Size([6706, 6706])\n",
      "st_embeddings shape: torch.Size([6706, 5])\n",
      "edge nums: 7960\n"
     ]
    }
   ],
   "source": [
    "method_df=pd.read_csv(method_dir)\n",
    "method_names=method_df[\"method name\"].tolist()\n",
    "method_simple_names=method_df[\"simple name\"].tolist()\n",
    "name2idx_dt={name:idx for idx,name in enumerate(method_names)}\n",
    "adj=torch.eye(len(method_names),dtype=torch.float)\n",
    "st_embeddings=torch.zeros((len(method_names),5),dtype=torch.float)\n",
    "print(f\"adj shape: {adj.shape}\")\n",
    "print(f\"st_embeddings shape: {st_embeddings.shape}\")\n",
    "\n",
    "callgraph_xml_root=ET.parse(callgraph_dir).getroot()\n",
    "namespace = {'graphml': 'http://graphml.graphdrawing.org/xmlns'}\n",
    "xml_edges = callgraph_xml_root.findall(\".//graphml:graph/graphml:edge\",namespace)\n",
    "print(f\"edge nums: {len(xml_edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources=method_df[\"method body\"]\n",
    "for i,source in enumerate(sources):\n",
    "    if type(source)==str:\n",
    "        st_embeddings[i][0]=len(source.split(\"\\n\"))\n",
    "    else:\n",
    "        st_embeddings[i][0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found size: 0\n"
     ]
    }
   ],
   "source": [
    "not_found=set()\n",
    "for xml_edge in xml_edges:\n",
    "    source_xml=xml_edge.get(\"source\")\n",
    "    target_xml=xml_edge.get(\"target\")\n",
    "    source_idx=method_name_match(source_xml,method_names,method_simple_names)\n",
    "    target_idx=method_name_match(target_xml,method_names,method_simple_names)\n",
    "    if source_idx!=-1 and target_idx!=-1:\n",
    "        adj[source_idx][target_idx]=1\n",
    "        st_embeddings[source_idx][1]+=1\n",
    "        st_embeddings[target_idx][2]+=1\n",
    "    if source_idx==-1:\n",
    "        not_found.add(source_xml)\n",
    "    if target_idx==-1:\n",
    "        not_found.add(target_xml)\n",
    "print(f\"not found size: {len(not_found)}\")\n",
    "for method in not_found:\n",
    "    print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_no_self = adj.clone().to(\"cuda\")\n",
    "adj_no_self.fill_diagonal_(0)\n",
    "st_embeddings = st_embeddings.to(\"cuda\")\n",
    "\n",
    "two_hop = adj_no_self @ adj_no_self\n",
    "\n",
    "for i in range(len(method_names)):\n",
    "    st_embeddings[i][3] = torch.sum(adj_no_self[i]).item()\n",
    "    \n",
    "    two_hop_node = (two_hop[i] > 0).float()\n",
    "    two_hop_node[adj_no_self[i] > 0] = 0.0\n",
    "    two_hop_node[i] = 0.0\n",
    "    st_embeddings[i][4] = torch.sum(two_hop_node).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file save to dir: .\\datasets\\embeddings\\commons-collections\\st_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "print(f\"file save to dir: {st_embedding_pt_dir}\")\n",
    "torch.save(st_embeddings,st_embedding_pt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commons-collections\n",
      "torch.Size([6706, 5])\n"
     ]
    }
   ],
   "source": [
    "print(project_name)\n",
    "print(st_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
