{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from MethodInfo import MethodInfo\n",
    "import MutantInfo\n",
    "importlib.reload(MutantInfo)\n",
    "from MutantInfo import MutantInfo\n",
    "import GraphModelContrastivev5\n",
    "importlib.reload(GraphModelContrastivev5)\n",
    "from GraphModelContrastivev5 import GraphModelContrastivev5, KFilter, KFilter_Multihead,KNFilter\n",
    "import ChangeImpactDataBuilder\n",
    "from ChangeImpactDataBuilder import ChangeImpactDataBuilder\n",
    "from ChangeImpactMutantIndicesDataset import ChangeImpactMutantIndicesDataset\n",
    "from ChangeImpactNodeIndicesDataset import ChangeImpactNodeIndicesDataset\n",
    "from util import my_collate_fn\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=tensorboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_indices=True\n",
    "device=\"cuda\"\n",
    "\n",
    "load_model_epoch=0\n",
    "new_filter=False\n",
    "\n",
    "dataset_split=0.8\n",
    "k_set=set([5,10,20,30,40])\n",
    "debug=False\n",
    "\n",
    "mutant_batch_size_train=400\n",
    "node_batch_size_train=7000\n",
    "mutant_batch_size_test=400\n",
    "node_batch_size_test=7000\n",
    "\n",
    "infonce_temperature=0.1\n",
    "\n",
    "clip_grad=False\n",
    "max_norm=20\n",
    "\n",
    "epoches=500\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_info=MethodInfo()\n",
    "mutant_info=MutantInfo(method_info,debug=False,\n",
    "                       mutant_info_dir=mutant_info_dir,\n",
    "                       mutant_execrecord_home=mutant_execrecord_home)\n",
    "mutant_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fix_indices:\n",
    "    train_indices=np.load(model_state_home+f\"{path_sep}train_indices.npy\").tolist()\n",
    "    test_indices=np.load(model_state_home+f\"{path_sep}test_indices.npy\").tolist()\n",
    "    print(f\"load model from epoch: {load_model_epoch}\\n\")\n",
    "else:\n",
    "    sample_indices=list(range(mutant_info.n_change))\n",
    "    random.shuffle(sample_indices)\n",
    "    split_index=int(mutant_info.n_change*dataset_split)\n",
    "    train_indices=sample_indices[:split_index]\n",
    "    test_indices=sample_indices[split_index:]\n",
    "    np.save(model_state_home+f\"{path_sep}train_indices.npy\",np.array(train_indices))\n",
    "    np.save(model_state_home+f\"{path_sep}test_indices.npy\",np.array(test_indices))\n",
    "\n",
    "if debug:\n",
    "    train_indices=[i for i in range(800)]\n",
    "    test_indices=[i+200 for i in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_builder=ChangeImpactDataBuilder(method_info,mutant_info)\n",
    "\n",
    "node_dataset=ChangeImpactNodeIndicesDataset(method_info)\n",
    "node_loader_train=DataLoader(node_dataset,batch_size=node_batch_size_train,shuffle=True,collate_fn=my_collate_fn)\n",
    "\n",
    "node_dataset_test=ChangeImpactNodeIndicesDataset(method_info)\n",
    "node_loader_test=DataLoader(node_dataset,batch_size=node_batch_size_test,collate_fn=my_collate_fn)\n",
    "\n",
    "mutant_dataset_train=ChangeImpactMutantIndicesDataset(train_indices)\n",
    "mutant_loader_train=DataLoader(mutant_dataset_train,batch_size=mutant_batch_size_train,shuffle=True,collate_fn=my_collate_fn)\n",
    "\n",
    "mutant_dataset_test=ChangeImpactMutantIndicesDataset(test_indices)\n",
    "mutant_loader_test=DataLoader(mutant_dataset_test,batch_size=mutant_batch_size_test,collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GraphModelContrastivev5(fusion_type=\"Union\")\n",
    "# model = GraphModelContrastivev5(fusion_type=\"Intersection\")\n",
    "model = GraphModelContrastivev5(fusion_type=\"Attention\")\n",
    "# model_filter = KFilter(h_token=512*2)\n",
    "model_filter = KFilter(h_token=768)\n",
    "kn_filter:bool=False\n",
    "\n",
    "if load_model_epoch != -1:\n",
    "    # cache_model_state_home=model_state_home\n",
    "    # cache_load_model_epoch=load_model_epoch\n",
    "    # model_state_home=f\".{path_sep}state\"+f\"{path_sep}\"+\"commons-collections\"\n",
    "    # load_model_epoch=183\n",
    "    # checkpoint = torch.load(model_state_home + f\"{path_sep}checkpoint_{load_model_epoch}.pth\")\n",
    "    checkpoint = torch.load(f\"D:\\workspace\\coding\\python\\defect2\\contrastivemodel_serverv3\\state\\commons-lang\\checkpoint_kfilter_pick01.pth\")\n",
    "    # model_state_home=cache_model_state_home\n",
    "    # load_model_epoch=cache_load_model_epoch\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if \"filter_type\" in checkpoint and checkpoint['filter_type'] is type(model_filter) and not new_filter:\n",
    "        try:\n",
    "            model_filter.load_state_dict(checkpoint['model_filter_state_dict'])\n",
    "        except:\n",
    "            model_filter.initialize_model()\n",
    "    else:\n",
    "        model_filter.initialize_model()\n",
    "    grad_step=checkpoint[\"grad_step\"]\n",
    "else:\n",
    "    model.initialize_model()\n",
    "    model_filter.initialize_model()\n",
    "\n",
    "model.to(device)\n",
    "model_filter.to(device)\n",
    "no_decay = ['bias']\n",
    "param_groups = [\n",
    "    {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": 1e-4},\n",
    "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "]\n",
    "param_groups_filter = [\n",
    "    {\"params\": [p for n, p in model_filter.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": 1e-4},\n",
    "    {\"params\": [p for n, p in model_filter.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "]\n",
    "optimizer = optim.Adam(param_groups, lr=0.001)\n",
    "optimizer_filter = optim.Adam(param_groups_filter, lr=0.001)\n",
    "\n",
    "if load_model_epoch != -1:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if \"filter_type\" in checkpoint and checkpoint['filter_type'] is type(model_filter) and not new_filter:\n",
    "        try:\n",
    "            optimizer_filter.load_state_dict(checkpoint['optimizer_filter_state_dict'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if load_model_epoch!=-1:\n",
    "    start_epoch=load_model_epoch+1\n",
    "else:\n",
    "    start_epoch=0\n",
    "\n",
    "total_batch_train=len(mutant_loader_train)*len(node_loader_train)\n",
    "total_batch_test=len(mutant_loader_test)*len(node_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_binary_labels(y_true, smoothing=0.1):\n",
    "    return y_true * (1 - smoothing) + 0.5 * smoothing\n",
    "\n",
    "\n",
    "def evaluate_limit(node_predict_indexs:torch.Tensor,\n",
    "                   node_predict_labels:torch.Tensor,\n",
    "                   node_predict_types:torch.Tensor,\n",
    "                   similarities:torch.Tensor,\n",
    "                   node_mutant_predict_indexs:list,\n",
    "                   node_predict_indexs_origintorch:torch.Tensor,\n",
    "                   in_callgraph:bool,\n",
    "                   in_history:bool,\n",
    "                   training:bool=True,\n",
    "                   model_filter=None,\n",
    "                   optimizer_filter:optim.Optimizer=None,\n",
    "                   target_embeddings:torch.Tensor=None,\n",
    "                   source_embeddings:torch.Tensor=None,\n",
    "                   filter:bool=False,\n",
    "                   filter_train_step:int=0):\n",
    "    if training:\n",
    "        model_filter.train()\n",
    "    else:\n",
    "        model_filter.eval()\n",
    "        \n",
    "    precision={k:[] for k in k_set}\n",
    "    recall={k:[] for k in k_set}\n",
    "    f1score={k:[] for k in k_set}\n",
    "    k_fp={k:0 for k in k_set}\n",
    "    k_fn={k:0 for k in k_set}\n",
    "    k_tp={k:0 for k in k_set}\n",
    "    loss_bi_logs={k:0 for k in k_set}\n",
    "\n",
    "    unique_types = torch.unique(node_predict_types)\n",
    "    node_predict_labels=node_predict_labels.to(similarities.device)\n",
    "    optimizer_filter.zero_grad()\n",
    "    for node_type in unique_types:\n",
    "        indices = (node_predict_types == node_type).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        mutant_index=node_mutant_predict_indexs[indices[0]]\n",
    "        candidate_indexs=mutant_info.get_candidate_node(mutant_index,\n",
    "                                                        in_callgraph=in_callgraph,\n",
    "                                                        in_history=in_history)\n",
    "        \n",
    "        candidate_set = set(candidate_indexs)\n",
    "        candidate_mask = torch.tensor([idx.item() in candidate_set for idx in node_predict_indexs_origintorch[indices]], device=indices.device,dtype=torch.bool)\n",
    "        \n",
    "        filtered_indices = indices[candidate_mask]\n",
    "\n",
    "        current_similarities = similarities[filtered_indices]\n",
    "        current_labels = node_predict_labels[filtered_indices]\n",
    "        cur_embeddings = target_embeddings[filtered_indices]\n",
    "\n",
    "        sorted_indices = torch.argsort(current_similarities, descending=True)\n",
    "\n",
    "        for k in k_set:\n",
    "            top_k_indices = sorted_indices[:k]\n",
    "            top_k_labels = current_labels[top_k_indices].view(-1).float()\n",
    "\n",
    "            if training and (k == 40 or kn_filter):\n",
    "                model_filter.train()\n",
    "            elif training and k != 40:\n",
    "                model_filter.eval()\n",
    "\n",
    "            if len(sorted_indices)!=0:\n",
    "                if training and (k == 40 or kn_filter):\n",
    "                    logits_bi = model_filter.forward_bi(cur_embeddings[top_k_indices],source_embeddings[node_type],k)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        logits_bi = model_filter.forward_bi(cur_embeddings[top_k_indices],source_embeddings[node_type],k)\n",
    "                pred_labels = (torch.sigmoid(logits_bi) > 0.5)\n",
    "                pos_weight = torch.tensor([3.0], device=logits_bi.device)\n",
    "                if training:\n",
    "                    loss_bi:torch.Tensor = F.binary_cross_entropy_with_logits(logits_bi,smooth_binary_labels(top_k_labels),\n",
    "                                                                            pos_weight=pos_weight)\n",
    "                else:\n",
    "                    loss_bi:torch.Tensor = F.binary_cross_entropy_with_logits(logits_bi,top_k_labels,\n",
    "                                                                          pos_weight=pos_weight)\n",
    "                    \n",
    "                if training and (k==40 or kn_filter):\n",
    "                    loss_bi.backward()\n",
    "                loss_bi_logs[k]+=loss_bi.item()\n",
    "\n",
    "            if filter and len(sorted_indices)!=0:\n",
    "                tp = int(torch.sum(top_k_labels[pred_labels]).item())\n",
    "                fp = int((pred_labels.sum() - tp).item())\n",
    "                fn = int(torch.sum(node_predict_labels[indices]).item() - tp)\n",
    "            else:\n",
    "                tp = int(torch.sum(top_k_labels).item())\n",
    "                fp = int(top_k_indices.shape[0] - tp)\n",
    "                fn = int(torch.sum(node_predict_labels[indices]).item() - tp)\n",
    "            \n",
    "            if (tp+fp)==0:\n",
    "                if (tp+fn)==0:\n",
    "                    precision_k = 1.0\n",
    "                else:\n",
    "                    precision_k = 0.0\n",
    "            else:\n",
    "                precision_k = tp / (tp + fp)\n",
    "            precision[k].append(precision_k)\n",
    "\n",
    "            if (tp + fn)!=0:\n",
    "                recall_k = tp / (tp + fn)\n",
    "                recall[k].append(recall_k)\n",
    "                if (precision_k+recall_k)==0:\n",
    "                    f1score_k = 0.0\n",
    "                else:\n",
    "                    f1score_k = 2 * (precision_k * recall_k) / (precision_k + recall_k)\n",
    "                f1score[k].append(f1score_k)\n",
    "            \n",
    "            k_fp[k]+=fp\n",
    "            k_fn[k]+=fn\n",
    "            k_tp[k]+=tp\n",
    "\n",
    "    if training:\n",
    "        total_norm = 0.0\n",
    "        for name, param in model_filter.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                total_norm += (param.grad.data.norm(2).item()) ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "        writer.add_scalar(\"Gradients/Filter/Total_Norm\", total_norm, filter_train_step)\n",
    "        optimizer_filter.step()\n",
    "\n",
    "    return precision, recall, f1score, k_fp, k_fn, k_tp, loss_bi_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_info.parse_mutant_impact_history(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=0\n",
    "info_train_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"start from epoch: {start_epoch}\\n\")\n",
    "for epoch in tqdm(range(start_epoch,epoches)):\n",
    "    if (epoch%4) in [0,1]:\n",
    "        filter=False\n",
    "        training_filter=False\n",
    "    else:\n",
    "        filter=True\n",
    "        training_filter=True\n",
    "    filter=True\n",
    "    training_filter=True\n",
    "    iter_loss_infonce=0\n",
    "    if training_filter:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    loss_bi_logs={k:0 for k in k_set}\n",
    "    for mutant_indexs in tqdm(mutant_loader_train):\n",
    "        for node_indexs in node_loader_train:\n",
    "            change_embeddings,node_embeddings,edge_indexs,node_predict_indexs,node_predict_labels,node_predict_types,node_change_indexs,node_mutant_predict_indexs,node_predict_indexs_origin,st_embeddings=data_builder.build_batch_data(mutant_indexs,node_indexs)\n",
    "            change_embeddings=change_embeddings.to(device)\n",
    "            node_embeddings=node_embeddings.to(device)\n",
    "            st_embeddings=st_embeddings.to(device)\n",
    "\n",
    "            edge_indexs=edge_indexs.to(device)\n",
    "\n",
    "            if training_filter:\n",
    "                with torch.no_grad():\n",
    "                    loss_infonce,similarities,target_embeddings,source_embeddings=model.forward(change_embeddings,node_embeddings,\n",
    "                                                                                                edge_indexs,node_predict_indexs,\n",
    "                                                                                                node_predict_types,\n",
    "                                                                                                node_predict_labels,node_change_indexs,\n",
    "                                                                                                st_embeddings,\n",
    "                                                                                                infonce_temperature=infonce_temperature,\n",
    "                                                                                                )\n",
    "            else:\n",
    "                loss_infonce,similarities,target_embeddings,source_embeddings=model.forward(change_embeddings,node_embeddings,\n",
    "                                                                                            edge_indexs,node_predict_indexs,\n",
    "                                                                                            node_predict_types,\n",
    "                                                                                            node_predict_labels,node_change_indexs,\n",
    "                                                                                            st_embeddings,\n",
    "                                                                                            infonce_temperature=infonce_temperature,\n",
    "                                                                                            )\n",
    "            \n",
    "            if not training_filter:\n",
    "                optimizer.zero_grad()\n",
    "                loss_infonce.backward()\n",
    "                total_norm = 0.0\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        total_norm += (param.grad.data.norm(2).item()) ** 2\n",
    "                total_norm = total_norm ** 0.5\n",
    "                writer.add_scalar(\"Gradients/Info/Total_Norm\", total_norm, info_train_step)\n",
    "                info_train_step+=1\n",
    "                if clip_grad:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "                optimizer.step()\n",
    "            \n",
    "            iter_loss_infonce+=loss_infonce.item()\n",
    "\n",
    "            if training_filter:\n",
    "                _,_,_,_,_,_,loss_bi_logs_cur=evaluate_limit(node_predict_indexs,node_predict_labels,\n",
    "                                                            node_predict_types,similarities.squeeze(-1),\n",
    "                                                            node_mutant_predict_indexs,\n",
    "                                                            node_predict_indexs_origin,\n",
    "                                                            in_callgraph=True,\n",
    "                                                            in_history=True,\n",
    "                                                            training=training_filter,\n",
    "                                                            model_filter=model_filter,\n",
    "                                                            optimizer_filter=optimizer_filter,\n",
    "                                                            target_embeddings=target_embeddings,\n",
    "                                                            source_embeddings=source_embeddings,\n",
    "                                                            filter=filter,\n",
    "                                                            filter_train_step=step)\n",
    "\n",
    "                for k in k_set:\n",
    "                    loss_bi_logs[k]+=loss_bi_logs_cur[k]\n",
    "\n",
    "                step+=1\n",
    "    \n",
    "    iter_loss_infonce=iter_loss_infonce/total_batch_train\n",
    "    writer.add_scalar(\"Loss/train/infonce\", iter_loss_infonce, epoch)\n",
    "    print(f\"epoch {epoch} train loss infonce: {iter_loss_infonce}\")\n",
    "    if training_filter:\n",
    "        for k in k_set:\n",
    "            loss_bi_logs[k]=loss_bi_logs[k]/total_batch_train\n",
    "            writer.add_scalar(f\"Loss/train/bi-{k}\", loss_bi_logs[k], epoch)\n",
    "            print(f\"epoch {epoch} train loss {k}-bi: {loss_bi_logs[k]}\")\n",
    "\n",
    "    # test\n",
    "    iter_loss_infonce=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if (epoch+1)%1==0:\n",
    "            all_precision={k:[] for k in k_set}\n",
    "            all_recall={k:[] for k in k_set}\n",
    "            k_fp={k:0 for k in k_set}\n",
    "            k_fn={k:0 for k in k_set}\n",
    "            k_tp={k:0 for k in k_set}\n",
    "            loss_bi_logs={k:0 for k in k_set}\n",
    "            for mutant_indexs in tqdm(mutant_loader_test):\n",
    "                for node_indexs in node_loader_test:\n",
    "                    change_embeddings,node_embeddings,edge_indexs,node_predict_indexs,node_predict_labels,node_predict_types,node_change_indexs,node_mutant_predict_indexs,node_predict_indexs_origin,st_embeddings=data_builder.build_batch_data(mutant_indexs,node_indexs)\n",
    "                    change_embeddings=change_embeddings.to(device)\n",
    "                    st_embeddings=st_embeddings.to(device)\n",
    "                    node_embeddings=node_embeddings.to(device)\n",
    "                    edge_indexs=edge_indexs.to(device)\n",
    "\n",
    "                    loss_infonce,similarities,target_embeddings,source_embeddings=model.forward(change_embeddings,node_embeddings,\n",
    "                                                                                                edge_indexs,node_predict_indexs,\n",
    "                                                                                                node_predict_types,\n",
    "                                                                                                node_predict_labels,node_change_indexs,\n",
    "                                                                                                st_embeddings,\n",
    "                                                                                                infonce_temperature=infonce_temperature)\n",
    "\n",
    "                    precision,recall,f1socre,cur_k_fp,cur_k_fn,cur_k_tp,loss_bi_logs_cur=evaluate_limit(node_predict_indexs,node_predict_labels,\n",
    "                                                                                                        node_predict_types,similarities.squeeze(-1),\n",
    "                                                                                                        node_mutant_predict_indexs,\n",
    "                                                                                                        node_predict_indexs_origin,\n",
    "                                                                                                        in_callgraph=True,\n",
    "                                                                                                        in_history=True,\n",
    "                                                                                                        training=False,\n",
    "                                                                                                        model_filter=model_filter,\n",
    "                                                                                                        optimizer_filter=optimizer_filter,\n",
    "                                                                                                        target_embeddings=target_embeddings,\n",
    "                                                                                                        source_embeddings=source_embeddings,\n",
    "                                                                                                        filter=filter)\n",
    "                    \n",
    "                    for k in k_set:\n",
    "                        all_precision[k]+=precision[k]\n",
    "                        all_recall[k]+=recall[k]\n",
    "                        k_fp[k]+=cur_k_fp[k]\n",
    "                        k_fn[k]+=cur_k_fn[k]\n",
    "                        k_tp[k]+=cur_k_tp[k]\n",
    "                        loss_bi_logs[k]+=loss_bi_logs_cur[k]\n",
    "\n",
    "                    iter_loss_infonce+=loss_infonce.item()\n",
    "\n",
    "            iter_loss_infonce=iter_loss_infonce/total_batch_test\n",
    "            print(f\"epoch {epoch} test loss infonce: {iter_loss_infonce}\")\n",
    "            writer.add_scalar(\"Loss/test/infonce\", iter_loss_infonce, epoch)\n",
    "\n",
    "            for k in k_set:\n",
    "                loss_bi_logs[k]=loss_bi_logs[k]/total_batch_test\n",
    "                writer.add_scalar(f\"Loss/test/bi-{k}\", loss_bi_logs[k], epoch)\n",
    "                print(f\"epoch {epoch} test loss {k}-bi: {loss_bi_logs[k]}\")\n",
    "                precision=sum(all_precision[k])/len(all_precision[k])\n",
    "                recall=sum(all_recall[k])/len(all_recall[k])\n",
    "                fscore=2*precision*recall/(precision+recall)\n",
    "                print(f\"k [{k}] FP: {k_fp[k]}\")\n",
    "                print(f\"k [{k}] FN: {k_fn[k]}\")\n",
    "                print(f\"k [{k}] TP: {k_tp[k]}\")\n",
    "                print(f\"k [{k}] precision: {precision}\")\n",
    "                print(f\"k [{k}] recall: {recall}\")\n",
    "                print(f\"k [{k}] fscore: {fscore}\\n\")\n",
    "                writer.add_scalar(f\"Metric/test/{k}/Precision\", precision, epoch)\n",
    "                writer.add_scalar(f\"Metric/test/{k}/Recall\", recall, epoch)\n",
    "                writer.add_scalar(f\"Metric/test/{k}/FScore\", fscore, epoch)\n",
    "            \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'grad_step': grad_step,\n",
    "        'filter_type': type(model_filter),\n",
    "        'model_filter_state_dict': model_filter.state_dict(),\n",
    "        'optimizer_filter_state_dict': optimizer_filter.state_dict(),\n",
    "    }, model_state_home + f\"{path_sep}checkpoint_{epoch}.pth\")\n",
    "    print(f\"Model state save to: {model_state_home}{path_sep}checkpoint_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_filter=model_filter\n",
    "\n",
    "model.to(device)\n",
    "pick_filter.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loss_infonce=0\n",
    "model.eval()\n",
    "all_precision={k:[] for k in k_set}\n",
    "all_recall={k:[] for k in k_set}\n",
    "k_fp={k:0 for k in k_set}\n",
    "k_fn={k:0 for k in k_set}\n",
    "k_tp={k:0 for k in k_set}\n",
    "loss_bi_logs={k:0 for k in k_set}\n",
    "for mutant_indexs in tqdm(mutant_loader_test):\n",
    "    for node_indexs in node_loader_test:\n",
    "        change_embeddings,node_embeddings,edge_indexs,node_predict_indexs,node_predict_labels,node_predict_types,node_change_indexs,node_mutant_predict_indexs,node_predict_indexs_origin,st_embeddings=data_builder.build_batch_data(mutant_indexs,node_indexs)\n",
    "        change_embeddings=change_embeddings.to(device)\n",
    "        st_embeddings=st_embeddings.to(device)\n",
    "        node_embeddings=node_embeddings.to(device)\n",
    "        edge_indexs=edge_indexs.to(device)\n",
    "        loss_infonce,similarities,target_embeddings,source_embeddings=model.forward(change_embeddings,node_embeddings,\n",
    "                                                                                    edge_indexs,node_predict_indexs,\n",
    "                                                                                    node_predict_types,\n",
    "                                                                                    node_predict_labels,node_change_indexs,\n",
    "                                                                                    st_embeddings,\n",
    "                                                                                    infonce_temperature=infonce_temperature)\n",
    "        precision,recall,f1socre,cur_k_fp,cur_k_fn,cur_k_tp,loss_bi_logs_cur=evaluate_limit(node_predict_indexs,node_predict_labels,\n",
    "                                                                                            node_predict_types,similarities.squeeze(-1),\n",
    "                                                                                            node_mutant_predict_indexs,\n",
    "                                                                                            node_predict_indexs_origin,\n",
    "                                                                                            in_callgraph=True,\n",
    "                                                                                            in_history=True,\n",
    "                                                                                            training=False,\n",
    "                                                                                            model_filter=model_filter,\n",
    "                                                                                            optimizer_filter=optimizer_filter,\n",
    "                                                                                            target_embeddings=target_embeddings,\n",
    "                                                                                            source_embeddings=source_embeddings,\n",
    "                                                                                            filter=False)\n",
    "    \n",
    "    for k in k_set:\n",
    "        all_precision[k]+=precision[k]\n",
    "        all_recall[k]+=recall[k]\n",
    "        k_fp[k]+=cur_k_fp[k]\n",
    "        k_fn[k]+=cur_k_fn[k]\n",
    "        k_tp[k]+=cur_k_tp[k]\n",
    "        loss_bi_logs[k]+=loss_bi_logs_cur[k]\n",
    "    iter_loss_infonce+=loss_infonce.item()\n",
    "iter_loss_infonce=iter_loss_infonce/total_batch_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_set:\n",
    "    precision=sum(all_precision[k])/len(all_precision[k])\n",
    "    recall=sum(all_recall[k])/len(all_recall[k])\n",
    "    fscore=2*precision*recall/(precision+recall)\n",
    "    print(f\"k [{k}] FP: {k_fp[k]}\")\n",
    "    print(f\"k [{k}] FN: {k_fn[k]}\")\n",
    "    print(f\"k [{k}] TP: {k_tp[k]}\")\n",
    "    print(f\"k [{k}] precision: {precision}\")\n",
    "    print(f\"k [{k}] recall: {recall}\")\n",
    "    print(f\"k [{k}] fscore: {fscore}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
